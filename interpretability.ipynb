{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"mimic3\"\n",
    "task=\"mortality\"\n",
    "kg =\"GPT-KG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/kgc/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling direct ehr nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9717/9717 [00:00<00:00, 18743.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset...\n",
      "Getting embedding...\n",
      "Getting dataloader...\n"
     ]
    }
   ],
   "source": [
    "from graphcare import *\n",
    "\n",
    "sample_dataset, G, ent2id, rel2id, ent_emb, rel_emb, \\\n",
    "            map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_rel_inv, \\\n",
    "                ccscm_id2clus, ccsproc_id2clus, atc3_id2clus = load_everything(dataset, task, kg)\n",
    "mode, out_channels, loss_function = get_mode_and_out_channels_and_loss_func(task=task, sample_dataset=sample_dataset)\n",
    "\n",
    "# label direct ehr node\n",
    "print(\"Labeling direct ehr nodes...\")\n",
    "sample_dataset = label_ehr_nodes(task, sample_dataset, len(map_cluster), ccscm_id2clus, ccsproc_id2clus, atc3_id2clus)\n",
    "print(\"Splitting dataset...\")\n",
    "train_dataset, val_dataset, test_dataset = split_by_patient(sample_dataset, [0.8, 0.1, 0.1], seed=528)\n",
    "G_tg = from_networkx(G)\n",
    "\n",
    "# get embedding\n",
    "print(\"Getting embedding...\")\n",
    "rel_emb = get_rel_emb(map_cluster_rel)\n",
    "node_emb = G_tg.x \n",
    "\n",
    "# get dataloader\n",
    "print(\"Getting dataloader...\")\n",
    "train_loader, val_loader, test_loader = get_dataloader(G_tg, train_dataset, val_dataset, test_dataset, task, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphCare(\n",
       "  (node_emb): Embedding(4599, 1536)\n",
       "  (rel_emb): Embedding(1077, 1536)\n",
       "  (lin): Linear(in_features=1536, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (alpha_attn): ModuleDict(\n",
       "    (1): Linear(in_features=4599, out_features=4599, bias=True)\n",
       "  )\n",
       "  (beta_attn): ModuleDict(\n",
       "    (1): Linear(in_features=4599, out_features=1, bias=True)\n",
       "  )\n",
       "  (conv): ModuleDict(\n",
       "    (1): BiAttentionGNNConv(nn=Linear(in_features=512, out_features=512, bias=True))\n",
       "  )\n",
       "  (bn_gnn): ModuleDict()\n",
       "  (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "  (relu): ReLU()\n",
       "  (tahh): Tanh()\n",
       "  (MLP): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphCare(\n",
    "    num_nodes=node_emb.shape[0],\n",
    "    num_rels=rel_emb.shape[0],\n",
    "    max_visit=sample_dataset[0]['visit_padded_node'].shape[0],\n",
    "    embedding_dim=node_emb.shape[1],\n",
    "    hidden_dim=512,\n",
    "    out_channels=out_channels,\n",
    "    layers=1,\n",
    "    dropout=0.5,\n",
    "    decay_rate=0.01,\n",
    "    node_emb=node_emb,\n",
    "    rel_emb=rel_emb,\n",
    "    patient_mode=\"joint\",\n",
    "    use_alpha=True,\n",
    "    use_beta=True,\n",
    "    use_edge_attn=True,\n",
    "    gnn=\"BAT\",\n",
    "    freeze=False\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(\n",
    "    dataset=dataset,\n",
    "    task=task,\n",
    "    mode=mode,\n",
    "    patient_mode=\"joint\",\n",
    "    gnn=model.gnn, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    loss_func=loss_function, \n",
    "    device=device, \n",
    "    epochs=20, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphCare(\n",
       "  (node_emb): Embedding(4599, 1536)\n",
       "  (rel_emb): Embedding(1077, 1536)\n",
       "  (lin): Linear(in_features=1536, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (alpha_attn): ModuleDict(\n",
       "    (1): Linear(in_features=4599, out_features=4599, bias=True)\n",
       "  )\n",
       "  (beta_attn): ModuleDict(\n",
       "    (1): Linear(in_features=4599, out_features=1, bias=True)\n",
       "  )\n",
       "  (conv): ModuleDict(\n",
       "    (1): BiAttentionGNNConv(nn=Linear(in_features=512, out_features=512, bias=True))\n",
       "  )\n",
       "  (bn_gnn): ModuleDict()\n",
       "  (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "  (relu): ReLU()\n",
       "  (tahh): Tanh()\n",
       "  (MLP): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ = GraphCare(\n",
    "    num_nodes=node_emb.shape[0],\n",
    "    num_rels=rel_emb.shape[0],\n",
    "    max_visit=sample_dataset[0]['visit_padded_node'].shape[0],\n",
    "    embedding_dim=node_emb.shape[1],\n",
    "    hidden_dim=512,\n",
    "    out_channels=out_channels,\n",
    "    layers=1,\n",
    "    dropout=0.5,\n",
    "    decay_rate=0.01,\n",
    "    node_emb=node_emb,\n",
    "    rel_emb=rel_emb,\n",
    "    patient_mode=\"joint\",\n",
    "    use_alpha=True,\n",
    "    use_beta=True,\n",
    "    use_edge_attn=True,\n",
    "    gnn=\"BAT\",\n",
    ")\n",
    "model_.load_state_dict(torch.load(f'../../../data/pj20/exp_data/saved_weights_{dataset}_{task}_BAT.pkl'))\n",
    "model_.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(991, 77)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "d_patient_ids = []\n",
    "\n",
    "for patient in val_dataset:\n",
    "    if patient['label'] == 1:\n",
    "        cnt += 1\n",
    "        d_patient_ids.append(patient['patient_id'])\n",
    "\n",
    "len(val_dataset), cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247/247 [00:26<00:00,  9.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loader = val_loader\n",
    "y_prob_all = []\n",
    "y_true_all = []\n",
    "patient_ids = []\n",
    "attentions = []\n",
    "edge_weights = []\n",
    "rel_ids_ = []\n",
    "\n",
    "data_ = None\n",
    "for data in tqdm(loader):\n",
    "    data_ = data\n",
    "    with torch.no_grad():\n",
    "        node_ids = data.y\n",
    "        rel_ids = data.relation\n",
    "        ehr_nodes = data.ehr_nodes.reshape(int(loader.batch_size), int(len(data.ehr_nodes)/loader.batch_size)).float()\n",
    "        visit_node = data.visit_padded_node.reshape(int(loader.batch_size), int(len(data.visit_padded_node)/loader.batch_size), data.visit_padded_node.shape[1]).float()\n",
    "\n",
    "        logits, alpha, beta, attn_w, rel_w = model_(\n",
    "                node_ids = node_ids, \n",
    "                rel_ids = rel_ids,\n",
    "                edge_index = data.edge_index,\n",
    "                batch = data.batch,\n",
    "                visit_node = visit_node,\n",
    "                ehr_nodes = ehr_nodes,\n",
    "                store_attn = True,\n",
    "\n",
    "            )\n",
    "        \n",
    "        y_prob = torch.sigmoid(logits)\n",
    "        y_true = data.label.reshape(int(loader.batch_size), int(len(data.label)/loader.batch_size))\n",
    "        y_prob_all.append(y_prob.cpu())\n",
    "        y_true_all.append(y_true.cpu())\n",
    "        for i in range(4):\n",
    "            if y_prob[i] >= 0.2 and y_true[i] == 1:\n",
    "                if data.patient_id[i] in d_patient_ids:\n",
    "                    attentions.append(alpha[0][i].cpu())\n",
    "                    edge_weights.append(rel_w[0].cpu())\n",
    "                    rel_ids_.append(rel_ids.cpu())\n",
    "                    patient_ids.append(data.patient_id[i])\n",
    "                    \n",
    "y_true_all = np.concatenate(y_true_all, axis=0)\n",
    "y_prob_all = np.concatenate(y_prob_all, axis=0)\n",
    "# np.where(y_true_all == 1)[0], y_prob_all[np.where(y_true_all == 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_patients = []\n",
    "\n",
    "for patient in val_dataset:\n",
    "    if patient['patient_id'] in patient_ids:\n",
    "        target_patients.append(patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_patient = target_patients[1]\n",
    "edge_weights = edge_weights[1]\n",
    "rel_ids = rel_ids_[1]\n",
    "attentions = attentions[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0023)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(edge_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "min_val = torch.min(edge_weights)\n",
    "max_val = torch.max(edge_weights)\n",
    "\n",
    "normed_edge_weights = (edge_weights - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1510],\n",
       "        [0.2756],\n",
       "        [0.2756],\n",
       "        ...,\n",
       "        [0.1532],\n",
       "        [0.1008],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_weights = {}\n",
    "\n",
    "for i in range(len(rel_ids)):\n",
    "    rel_weights[int(rel_ids[i])] =  float(normed_edge_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_rel_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = attentions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/pj20/exp_data/ccscm_ccsproc_atc3/clusters_th015.json\", 'r') as f:\n",
    "    map_cluster = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 1337.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2062.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "net = Network()\n",
    "Graph = nx.Graph()\n",
    "edge_labels = {}\n",
    "\n",
    "Graph.add_node(\"PATIENT\")\n",
    "\n",
    "conditions = target_patient['conditions'][0]\n",
    "procedures = target_patient['procedures'][0]\n",
    "drugs = target_patient['drugs'][0]\n",
    "\n",
    "node_set_all = set()\n",
    "node_set_list = []\n",
    "cluster_included_entities = defaultdict(list)\n",
    "cluster_included_relations = defaultdict(list)\n",
    "\n",
    "for condition in tqdm(conditions):\n",
    "\n",
    "    # add direct EHR node and edge\n",
    "    Graph.add_node(ccscm_id2clus[condition])\n",
    "    Graph.add_edge(\"PATIENT\", ccscm_id2clus[condition], label=\"condition\")\n",
    "\n",
    "\n",
    "    cond_file = f'./graphs/condition/CCSCM/{condition}.txt'\n",
    "    with open(cond_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        items = line.split('\\t')\n",
    "        try:\n",
    "            if len(items) == 3:\n",
    "                h, r, t = items\n",
    "                t = t[:-1]\n",
    "                h_id = ent2id[h]\n",
    "                t_id = ent2id[t]\n",
    "                r_id = rel2id[r]\n",
    "\n",
    "                h_node = int(map_cluster_inv[h_id])\n",
    "                t_node = int(map_cluster_inv[t_id])\n",
    "                r_edge = int(map_cluster_rel_inv[r_id])\n",
    "\n",
    "                cluster_included_entities[h_node].append(h)\n",
    "                cluster_included_entities[t_node].append(t)\n",
    "                cluster_included_relations[r_edge].append(r)\n",
    "\n",
    "                Graph.add_node(h_node, label=cluster_included_entities[h_node][0], weight=map_cluster[str(h_node)]['attention_mortality'])\n",
    "                Graph.add_node(t_node, label=cluster_included_entities[t_node][0], weight=map_cluster[str(t_node)]['attention_mortality'])\n",
    "                Graph.add_edge(h_node, t_node, label=cluster_included_relations[r_edge][0], weight=rel_weights[r_edge])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "for procedure in tqdm(procedures):\n",
    "    # add direct EHR node and edge\n",
    "    Graph.add_node(ccsproc_id2clus[procedure])\n",
    "    Graph.add_edge(\"PATIENT\", ccsproc_id2clus[procedure], label=\"procedure\")\n",
    "\n",
    "    proc_file = f'./graphs/procedure/CCSPROC/{procedure}.txt'\n",
    "    with open(proc_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        items = line.split('\\t')\n",
    "        try:\n",
    "            if len(items) == 3:\n",
    "                h, r, t = items\n",
    "                t = t[:-1]\n",
    "                h_id = ent2id[h]\n",
    "                t_id = ent2id[t]\n",
    "                r_id = rel2id[r]\n",
    "\n",
    "                h_node = int(map_cluster_inv[h_id])\n",
    "                t_node = int(map_cluster_inv[t_id])\n",
    "                r_edge = int(map_cluster_rel_inv[r_id])\n",
    "\n",
    "                cluster_included_entities[h_node].append(h)\n",
    "                cluster_included_entities[t_node].append(t)\n",
    "                cluster_included_relations[r_edge].append(r)\n",
    "\n",
    "                Graph.add_node(h_node, label=cluster_included_entities[h_node][0], weight=map_cluster[str(h_node)]['attention_mortality'])\n",
    "                Graph.add_node(t_node, label=cluster_included_entities[t_node][0], weight=map_cluster[str(t_node)]['attention_mortality'])\n",
    "                Graph.add_edge(h_node, t_node, label=cluster_included_relations[r_edge][0], weight=rel_weights[r_edge])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# for drug in tqdm(drugs):    \n",
    "#     Graph.add_node(atc3_id2clus[drug])\n",
    "#     Graph.add_edge(\"PATIENT\", atc3_id2clus[drug], label=\"drug\")\n",
    "#     drug_file = f'./graphs/drug/ATC3/{drug}.txt'\n",
    "\n",
    "#     with open(drug_file, 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "\n",
    "#     for line in lines:\n",
    "#         items = line.split('\\t')\n",
    "#         try:\n",
    "#             if len(items) == 3:\n",
    "#                 h, r, t = items\n",
    "#                 t = t[:-1]\n",
    "#                 h_id = ent2id[h]\n",
    "#                 t_id = ent2id[t]\n",
    "#                 r_id = rel2id[r]\n",
    "\n",
    "#                 h_node = map_cluster_inv[h_id]\n",
    "#                 t_node = map_cluster_inv[t_id]\n",
    "#                 r_edge = map_cluster_rel_inv[r_id]\n",
    "\n",
    "#                 cluster_included_entities[h_node].append(h)\n",
    "#                 cluster_included_entities[t_node].append(t)\n",
    "#                 cluster_included_relations[r_edge].append(r)\n",
    "\n",
    "#                 Graph.add_node(h_node)\n",
    "#                 Graph.add_node(t_node)\n",
    "#                 Graph.add_edge(h_node, t_node, label=r_edge)\n",
    "\n",
    "#         except:\n",
    "#             continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 4599)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(Graph, 'graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kgc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0509d9aa81f2882b18eeb72d4d23c32cae9029e9b99f63cde94ba86c35ac78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
