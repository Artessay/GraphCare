{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/kgc/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-02 23:11:22.022415: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 23:11:22.169216: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-02 23:11:22.682066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 23:11:22.682174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 23:11:22.682185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 GPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BioGptTokenizer, BioGptForCausalLM, set_seed\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/BioGPT-Large\")\n",
    "model = BioGptForCausalLM.from_pretrained(\"microsoft/BioGPT-Large\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)  # move model to the device\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(57717, 1600, padding_idx=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ampicillin is still the drug of choice in the treatment of gonorrhoea in the UK. < / FREETEXT > < / PARAGRAPH > ▃ < PARAGRAPH > < FREETEXT > Keywords: < / FREETEXT > < / PARAGRAPH > ▃ < PARAGRAPH > < FREETEXT > Gonorrhoea, Penicillinase-producing Neisseria gonorrhoeae (PPNG), Ceftriaxone, Azithromycin < / FREETEXT > < / PARAGRAPH > ▃ < PARAGRAPH > < FREETEXT > Gonorrhoea is a sexually transmitted infection (STI) caused by the Gram-negative diplococcus Neisseria gonorrhoeae. It is the second most common bacterial STI in the world, with an estimated 7 8 million new cases per year. In the UK, gonorrhoea is the most common bacterial STI in men who have sex with men (MSM) and the second most common bacterial STI in heterosexuals. < / FREETEXT > < / PARAGRAPH > ▃ < PARAGRAPH > < FREETEXT > Gonorrhoea is a major public health concern in the UK due to the emergence of antimicrobial resistance (AMR) to the recommended first-line treatment, ceftriaxone (CRO). In 2 0 1 6, the UK Department of Health (DH) reported that the prevalence of CRO-resistant N. gonorrhoeae (CRO r < / FREETEXT > < / PARAGRAPH > ▃ < PARAGRAPH > < FREETEXT > N. gonorrhoeae) in England and Wales had increased from 0. 3% in 2 0 1 5 to 1. 1% in 2 0 1 6. In 2 0 1 7, the prevalence of\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = \"Ampicillin is\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        beam_output = model.module.generate(inputs[\"input_ids\"],\n",
    "                                             attention_mask=inputs[\"attention_mask\"],\n",
    "                                             min_length=100,\n",
    "                                             max_length=300,\n",
    "                                             num_beams=5,\n",
    "                                             early_stopping=True\n",
    "                                            )\n",
    "    else:\n",
    "        beam_output = model.generate(inputs[\"input_ids\"],\n",
    "                                      attention_mask=inputs[\"attention_mask\"],\n",
    "                                      min_length=100,\n",
    "                                      max_length=300,\n",
    "                                      num_beams=5,\n",
    "                                      early_stopping=True\n",
    "                                     )\n",
    "\n",
    "output = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/kgc/lib/python3.8/site-packages/transformers/pipelines/token_classification.py:159: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoConfig, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "config_d = AutoConfig.from_pretrained(\"alvaroalon2/biobert_diseases_ner\")\n",
    "tokenizer_d = AutoTokenizer.from_pretrained(\"alvaroalon2/biobert_diseases_ner\", use_fast=True, return_offsets_mapping=True)\n",
    "model_d = AutoModelForTokenClassification.from_pretrained(\"alvaroalon2/biobert_diseases_ner\", config=config_d)\n",
    "\n",
    "config_c = AutoConfig.from_pretrained(\"alvaroalon2/biobert_chemical_ner\")\n",
    "tokenizer_c = AutoTokenizer.from_pretrained(\"alvaroalon2/biobert_chemical_ner\", use_fast=True, return_offsets_mapping=True)\n",
    "model_c = AutoModelForTokenClassification.from_pretrained(\"alvaroalon2/biobert_chemical_ner\", config=config_c)\n",
    "\n",
    "config_g = AutoConfig.from_pretrained(\"alvaroalon2/biobert_genetic_ner\")\n",
    "tokenizer_g = AutoTokenizer.from_pretrained(\"alvaroalon2/biobert_genetic_ner\", use_fast=True, return_offsets_mapping=True)\n",
    "model_g = AutoModelForTokenClassification.from_pretrained(\"alvaroalon2/biobert_genetic_ner\", config=config_g)\n",
    "\n",
    "\n",
    "# Create the NER pipeline\n",
    "ner_dis = pipeline(task=\"ner\", model=model_d, tokenizer=tokenizer_d, framework='pt', grouped_entities=True)\n",
    "ner_chem = pipeline(task=\"ner\", model=model_c, tokenizer=tokenizer_c, framework='pt', grouped_entities=True)\n",
    "ner_gene = pipeline(task=\"ner\", model=model_g, tokenizer=tokenizer_g, framework='pt', grouped_entities=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_entities(results):\n",
    "    filtered_results = []\n",
    "    for result in results:\n",
    "        entity_type = result['entity_group']\n",
    "        entity_text = result['word']\n",
    "        # Filter out entities that are too short or are all digits\n",
    "        if len(entity_text) > 1 and not entity_text.isdigit():\n",
    "            # Split the entity text into words and filter out short words and stop words\n",
    "            words = [word for word in entity_text.split() if len(word) > 2 and not re.match(r'^\\W+$', word)]\n",
    "            # If the entity has at least one valid word, add it to the filtered results\n",
    "            if len(words) > 0:\n",
    "                filtered_results.append((entity_type, ' '.join(words)))\n",
    "    return filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GENETIC', 'alpha adrenoceptor'), ('CHEMICAL', 'Xylazine'), ('CHEMICAL', '##ylazine'), ('0', 'Xylazine alpha adrenoceptor agonist that has been used sedative and analgesic veterinary medicine for many years, but its effects the cardiovascular system have not been extensively studied the dog, and its effects the central nervous system CNS have not been well characterized the dog, despite the fact that xylazine has been widely used sedative and analgesic veterinary medicine for more than years.')]\n"
     ]
    }
   ],
   "source": [
    "# Define the input text\n",
    "text = \"Xylazine is an alpha 2-adrenoceptor agonist that has been used as a sedative and analgesic in veterinary medicine for many years, but its effects on the cardiovascular system have not been extensively studied in the dog, and its effects on the central nervous system (CNS) have not been well characterized in the dog, despite the fact that xylazine has been widely used as a sedative and analgesic in veterinary medicine for more than 30 years.\"\n",
    "\n",
    "# Run NER on the input text\n",
    "results = []\n",
    "results += ner_gene(text)\n",
    "results += ner_chem(text)\n",
    "results += ner_dis(text)\n",
    "\n",
    "filtered_results = filter_entities(results)\n",
    "print(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_entities = []\n",
    "\n",
    "# Iterate over the list of results\n",
    "for r in results:\n",
    "    # Check if the entity is a chemical\n",
    "    if r[\"entity_group\"] == \"CHEMICAL\":\n",
    "        # Combine the subword tokens into a single string\n",
    "        entity_text = \"\".join(r[\"word\"])\n",
    "        # Add the entity text to the list\n",
    "        chemical_entities.append(entity_text)\n",
    "\n",
    "# Print the list of chemical entities\n",
    "print(chemical_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kgc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0509d9aa81f2882b18eeb72d4d23c32cae9029e9b99f63cde94ba86c35ac78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
