{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"drugrec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'/data/pj20/exp_data/ccscm_ccsproc/sample_dataset_mimic3_{task}_th015.pkl', 'rb') as f:\n",
    "    sample_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44399"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = split_by_patient(sample_dataset, [0.8, 0.1, 0.1], train_ratio=1.0, seed=528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = list(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def nested_dict():\n",
    "    return defaultdict(list)\n",
    "\n",
    "def drop_ratio(d, ratio):\n",
    "    new_d = defaultdict(list)\n",
    "    for key, value in d.items():\n",
    "        if key == \"conditions\" or key == \"procedures\" or key == \"drugs\":\n",
    "            if isinstance(value[0], list):\n",
    "                for i in range(len(value)):\n",
    "                        n = int(len(value[i]) * (ratio))  # calculate the number of items to keep\n",
    "                        sampled = random.sample(value[i], n)  # randomly select items to keep\n",
    "                        if len(sampled) > 0:\n",
    "                            new_d[key].append(sampled)\n",
    "                        else:\n",
    "                            new_d[key].append(random.sample(value[i], 1))\n",
    "            else:\n",
    "                n = int(len(value) * (ratio))\n",
    "                sampled = random.sample(value, n)\n",
    "                if len(new_d[key]) == 0:\n",
    "                    new_d[key] = value\n",
    "                else:\n",
    "                    new_d[key] = random.sample(value, 1)\n",
    "        elif key == \"label\":\n",
    "            new_d[key] = value\n",
    "        else:\n",
    "            new_d[key] = value\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [\n",
    "    0.05,\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.3,\n",
    "    0.4,\n",
    "    0.5,\n",
    "    0.6,\n",
    "    0.7,\n",
    "    0.8,\n",
    "    0.9,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.05\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:07<00:00, 1043.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:07<00:00, 979.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.05\n",
      "ratio:  0.1\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:11<00:00, 655.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:11<00:00, 653.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.1\n",
      "ratio:  0.2\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:23<00:00, 334.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:21<00:00, 358.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.2\n",
      "ratio:  0.3\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:33<00:00, 230.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:30<00:00, 256.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.3\n",
      "ratio:  0.4\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:46<00:00, 167.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:39<00:00, 196.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.4\n",
      "ratio:  0.5\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:59<00:00, 130.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:48<00:00, 158.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.5\n",
      "ratio:  0.6\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [01:10<00:00, 109.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [00:57<00:00, 134.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.6\n",
      "ratio:  0.7\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [01:23<00:00, 92.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [01:04<00:00, 119.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.7\n",
      "ratio:  0.8\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [01:35<00:00, 80.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [01:12<00:00, 107.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.8\n",
      "ratio:  0.9\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [01:50<00:00, 70.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7730/7730 [01:21<00:00, 95.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ratio: 0.9\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from data_prepare import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "for ratio in ratios:\n",
    "    print(\"ratio: \", ratio)\n",
    "    train_instance = deepcopy(train_dataset)\n",
    "\n",
    "    for i in range(len(train_instance)):\n",
    "        train_instance[i] = drop_ratio(train_instance[i], ratio)\n",
    "\n",
    "    print(\"Loading embeddings...\")\n",
    "    ent2id, rel2id, ent_emb, rel_emb = load_embeddings(task)\n",
    "    if task == \"drugrec\":\n",
    "        train_instance = prepare_drug_indices(train_instance)\n",
    "\n",
    "    map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_inv_rel = clustering(task, ent_emb, rel_emb, threshold=0.15, load_cluster=True, save_cluster=False)\n",
    "\n",
    "    print(\"Processing graph...\")\n",
    "    G = process_graph(\"mimic3\", task, train_instance, ent2id, rel2id, map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_inv_rel, save_graph=False)\n",
    "    G_tg = from_networkx(G)\n",
    "    \n",
    "    print(\"Processing dataset...\")\n",
    "    train_instance = process_sample_dataset(\"mimic3\", task, train_instance, G_tg, ent2id, rel2id, map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_inv_rel, save_dataset=False)\n",
    "\n",
    "    with open(f'/data/pj20/exp_data/ccscm_ccsproc_atc3/train_dataset_mimic3_{task}_th015_{ratio}.pkl', 'wb') as f:\n",
    "        pickle.dump(train_instance, f)\n",
    "\n",
    "    print(f\"Done ratio: {ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kgc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0509d9aa81f2882b18eeb72d4d23c32cae9029e9b99f63cde94ba86c35ac78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
