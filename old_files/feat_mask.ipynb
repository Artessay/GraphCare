{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"lenofstay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/kgc/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'/data/pj20/exp_data/ccscm_ccsproc/sample_dataset_mimic3_{task}_th015.pkl', 'rb') as f:\n",
    "    sample_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.3,\n",
    "    # 0.4,\n",
    "    # 0.5,\n",
    "    # 0.6,\n",
    "    # 0.7,\n",
    "    # 0.8,\n",
    "    # 0.9,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from data_prepare import *\n",
    "\n",
    "\n",
    "def process(sample_dataset, task):\n",
    "    dataset_instance = deepcopy(sample_dataset)\n",
    "\n",
    "    print(\"Loading embeddings...\")\n",
    "    ent2id, rel2id, ent_emb, rel_emb = load_embeddings(task)\n",
    "    if task == \"drugrec\":\n",
    "        dataset_instance = prepare_drug_indices(dataset_instance)\n",
    "\n",
    "    map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_inv_rel = clustering(task, ent_emb, rel_emb, threshold=0.15, load_cluster=True, save_cluster=False)\n",
    "\n",
    "    print(\"Processing graph...\")\n",
    "    G = process_graph(\"mimic3\", task, dataset_instance, ent2id, rel2id, map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_inv_rel, save_graph=False)\n",
    "    G_tg = from_networkx(G)\n",
    "    \n",
    "    print(\"Processing dataset...\")\n",
    "    dataset_instance = process_sample_dataset(\"mimic3\", task, dataset_instance, G_tg, ent2id, rel2id, map_cluster, map_cluster_inv, map_cluster_rel, map_cluster_inv_rel, save_dataset=False)\n",
    "\n",
    "    return G, dataset_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.1\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:23<00:00, 1875.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:26<00:00, 1658.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.2\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:27<00:00, 1627.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:30<00:00, 1463.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.3\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:55<00:00, 806.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:57<00:00, 771.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.1\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:18<00:00, 2464.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:21<00:00, 2023.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.2\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:33<00:00, 1311.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:37<00:00, 1188.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.3\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:49<00:00, 903.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:51<00:00, 865.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.1\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:20<00:00, 2157.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:23<00:00, 1876.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.2\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:33<00:00, 1332.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:38<00:00, 1165.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio:  0.3\n",
      "Loading embeddings...\n",
      "Processing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:39<00:00, 1111.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44399/44399 [00:43<00:00, 1026.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(3):\n",
    "    for ratio in mask_ratio:\n",
    "        dataset_instance = deepcopy(sample_dataset)\n",
    "        remove_ratio = 1 - ratio\n",
    "        print(\"ratio: \", ratio)\n",
    "\n",
    "        conditions_to_remove = random.sample(dataset_instance.get_all_tokens('conditions'), int(len(dataset_instance.get_all_tokens('conditions')) * remove_ratio))\n",
    "        procedures_to_remove = random.sample(dataset_instance.get_all_tokens('procedures'), int(len(dataset_instance.get_all_tokens('procedures')) * remove_ratio))\n",
    "        drugs_to_remove = random.sample(dataset_instance.get_all_tokens('drugs'), int(len(dataset_instance.get_all_tokens('drugs')) * remove_ratio))\n",
    "\n",
    "        for patient in dataset_instance:\n",
    "            for visit in range(len(patient['conditions'])):\n",
    "                # relabel the tokens to remove as \"0\"\n",
    "                patient['conditions'][visit] = [c if c not in conditions_to_remove else \"0\" for c in patient['conditions'][visit]]\n",
    "                patient['procedures'][visit] = [p if p not in procedures_to_remove else \"0\" for p in patient['procedures'][visit]]\n",
    "                patient['drugs'][visit] = [d if d not in drugs_to_remove else \"0\" for d in patient['drugs'][visit]]\n",
    "\n",
    "        G, dataset_instance = process(dataset_instance, task)\n",
    "\n",
    "        with open(f'/data/pj20/exp_data/ccscm_ccsproc/sample_dataset_mimic3_{task}_th015_mask_{ratio}_{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(dataset_instance, f)\n",
    "        with open(f'/data/pj20/exp_data/ccscm_ccsproc/graph_mimic3_{task}_th015_mask_{ratio}_{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def process(d):\n",
    "    new_d = defaultdict(list)\n",
    "    for key, value in d.items():\n",
    "        if key == \"conditions\" or key == \"procedures\" or key == \"drugs\" or key == \"label\" or key == \"patient_id\" or key == \"visit_id\":\n",
    "            new_d[key] = value\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for j in range(3):\n",
    "    for ratio in voc_ratios:\n",
    "        with open(f'/data/pj20/exp_data/ccscm_ccsproc_atc3/sample_dataset_mimic3_{task}_th015_mask_{ratio}_{j}.pkl', 'rb') as f:\n",
    "            sample_dataset = pickle.load(f)\n",
    "    \n",
    "        sample_dataset = list(sample_dataset)\n",
    "        for i in range(len(sample_dataset)):\n",
    "            sample_dataset[i] = process(sample_dataset[i])\n",
    "        \n",
    "        with open(f'/data/pj20/exp_data/ccscm_ccsproc_atc3/sample_dataset_mimic3_{task}_th015_mask_{ratio}_{j}_pyhealth.pkl', 'wb') as f:\n",
    "            pickle.dump(sample_dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kgc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0509d9aa81f2882b18eeb72d4d23c32cae9029e9b99f63cde94ba86c35ac78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
