{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyhealth.datasets import MIMIC3Dataset, MIMIC4Dataset\n",
    "# from GraphCare.task_fn import drug_recommendation_fn, drug_recommendation_mimic4_fn, mortality_prediction_mimic3_fn, readmission_prediction_mimic3_fn, length_of_stay_prediction_mimic3_fn, length_of_stay_prediction_mimic4_fn, mortality_prediction_mimic4_fn, readmission_prediction_mimic4_fn\n",
    "\n",
    "# ds = MIMIC4Dataset(\n",
    "# root=\"/data/physionet.org/files/mimiciv/2.0/hosp/\", \n",
    "# tables=[\"diagnoses_icd\", \"procedures_icd\", \"prescriptions\"],      \n",
    "# code_mapping={\n",
    "#     \"NDC\": (\"ATC\", {\"target_kwargs\": {\"level\": 3}}),\n",
    "#     \"ICD9CM\": \"CCSCM\",\n",
    "#     \"ICD9PROC\": \"CCSPROC\",\n",
    "#     \"ICD10CM\": \"CCSCM\",\n",
    "#     \"ICD10PROC\": \"CCSPROC\",\n",
    "#     },\n",
    "# dev=False\n",
    "# )\n",
    "\n",
    "# sample_dataset = ds.set_task(drug_recommendation_mimic4_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"drugrec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'/data/pj20/exp_data/ccscm_ccsproc/sample_dataset_mimic4_{task}_th015_.pkl', 'rb') as f:\n",
    "    sample_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratios = \\\n",
    "[\n",
    "    # 0.001,\n",
    "    # 0.002,\n",
    "    # 0.003,\n",
    "    # 0.004,\n",
    "    # 0.005,\n",
    "    # 0.006,\n",
    "    # 0.007,\n",
    "    # 0.008,\n",
    "    # 0.009,\n",
    "    # 0.01,\n",
    "    # 0.02,\n",
    "    # 0.03,\n",
    "    # 0.04,\n",
    "    # 0.05,\n",
    "    # 0.06,\n",
    "    # 0.07,\n",
    "    # 0.08,\n",
    "    # 0.09,\n",
    "    # 0.1,\n",
    "    # 0.3,\n",
    "    # 0.5,\n",
    "    # 0.7,\n",
    "    # 0.9,\n",
    "    1.0,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (conditions): Embedding(273, 128, padding_idx=0)\n",
      "    (procedures): Embedding(216, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (rnn): ModuleDict(\n",
      "    (conditions): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "    (procedures): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=191, bias=True)\n",
      ")\n",
      "Metrics: ['pr_auc_samples', 'roc_auc_samples', 'f1_samples', 'jaccard_samples']\n",
      "Device: cuda:1\n",
      "\n",
      "Training:\n",
      "Batch size: 64\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fb588a3ce50>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 5\n",
      "\n",
      "Epoch 0 / 5: 100%|██████████| 120/120 [00:01<00:00, 74.45it/s]\n",
      "--- Train epoch-0, step-120 ---\n",
      "loss: 0.3303\n",
      "Evaluation: 100%|██████████| 15/15 [00:00<00:00, 139.62it/s]\n",
      "--- Eval epoch-0, step-120 ---\n",
      "pr_auc_samples: 0.6386\n",
      "roc_auc_samples: 0.9032\n",
      "f1_samples: 0.4860\n",
      "jaccard_samples: 0.3323\n",
      "loss: 0.2518\n",
      "New best pr_auc_samples score (0.6386) at epoch-0, step-120\n",
      "\n",
      "Epoch 1 / 5: 100%|██████████| 120/120 [00:01<00:00, 72.73it/s]\n",
      "--- Train epoch-1, step-240 ---\n",
      "loss: 0.2442\n",
      "Evaluation: 100%|██████████| 15/15 [00:00<00:00, 124.85it/s]\n",
      "--- Eval epoch-1, step-240 ---\n",
      "pr_auc_samples: 0.6656\n",
      "roc_auc_samples: 0.9148\n",
      "f1_samples: 0.5112\n",
      "jaccard_samples: 0.3592\n",
      "loss: 0.2326\n",
      "New best pr_auc_samples score (0.6656) at epoch-1, step-240\n",
      "\n",
      "Epoch 2 / 5: 100%|██████████| 120/120 [00:01<00:00, 75.26it/s]\n",
      "--- Train epoch-2, step-360 ---\n",
      "loss: 0.2315\n",
      "Evaluation: 100%|██████████| 15/15 [00:00<00:00, 113.37it/s]\n",
      "--- Eval epoch-2, step-360 ---\n",
      "pr_auc_samples: 0.6786\n",
      "roc_auc_samples: 0.9190\n",
      "f1_samples: 0.5393\n",
      "jaccard_samples: 0.3858\n",
      "loss: 0.2264\n",
      "New best pr_auc_samples score (0.6786) at epoch-2, step-360\n",
      "\n",
      "Epoch 3 / 5: 100%|██████████| 120/120 [00:01<00:00, 63.37it/s]\n",
      "--- Train epoch-3, step-480 ---\n",
      "loss: 0.2248\n",
      "Evaluation: 100%|██████████| 15/15 [00:00<00:00, 129.44it/s]\n",
      "--- Eval epoch-3, step-480 ---\n",
      "pr_auc_samples: 0.6873\n",
      "roc_auc_samples: 0.9230\n",
      "f1_samples: 0.5386\n",
      "jaccard_samples: 0.3863\n",
      "loss: 0.2221\n",
      "New best pr_auc_samples score (0.6873) at epoch-3, step-480\n",
      "\n",
      "Epoch 4 / 5: 100%|██████████| 120/120 [00:01<00:00, 70.40it/s]\n",
      "--- Train epoch-4, step-600 ---\n",
      "loss: 0.2206\n",
      "Evaluation: 100%|██████████| 15/15 [00:00<00:00, 123.36it/s]\n",
      "--- Eval epoch-4, step-600 ---\n",
      "pr_auc_samples: 0.6906\n",
      "roc_auc_samples: 0.9246\n",
      "f1_samples: 0.5444\n",
      "jaccard_samples: 0.3916\n",
      "loss: 0.2203\n",
      "New best pr_auc_samples score (0.6906) at epoch-4, step-600\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 15/15 [00:00<00:00, 127.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "\n",
    "for train_ratio in train_ratios:\n",
    "    train_dataset, val_dataset, test_dataset = split_by_patient(sample_dataset, [0.8, 0.1, 0.1], train_ratio=train_ratio, seed=528)\n",
    "    train_loader = get_dataloader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = get_dataloader(val_dataset, batch_size=64, shuffle=False)\n",
    "    test_loader = get_dataloader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "    from pyhealth.trainer import Trainer\n",
    "    import torch\n",
    "    from pyhealth.models import Transformer, RETAIN, SafeDrug, MICRON, CNN, RNN, GAMENet\n",
    "    from collections import defaultdict\n",
    "\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for i in range(1):\n",
    "        for model_ in [\n",
    "            RNN,\n",
    "            # Transformer, \n",
    "            # RETAIN,\n",
    "            # SafeDrug,\n",
    "            # MICRON,\n",
    "            # GAMENet\n",
    "            ]:\n",
    "            try:\n",
    "                model = model_(\n",
    "                    dataset=sample_dataset,\n",
    "                    feature_keys=[\"conditions\", \"procedures\"],\n",
    "                    label_key=\"drugs\",\n",
    "                    mode=\"multilabel\",\n",
    "                )\n",
    "            except:\n",
    "                model = model_(dataset=sample_dataset)\n",
    "\n",
    "            device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            ## binary\n",
    "            # trainer = Trainer(model=model, device=device, metrics=[\"pr_auc\", \"roc_auc\", \"accuracy\", \"f1\", \"jaccard\"])\n",
    "            # trainer.train(\n",
    "            #     train_dataloader=train_loader,\n",
    "            #     val_dataloader=val_loader,\n",
    "            #     epochs=5,\n",
    "            #     monitor=\"accuracy\",\n",
    "            # )\n",
    "\n",
    "            ## multi-label\n",
    "            trainer = Trainer(model=model, device=device, metrics=[\"pr_auc_samples\", \"roc_auc_samples\", \"f1_samples\", \"jaccard_samples\"])\n",
    "            trainer.train(\n",
    "                train_dataloader=train_loader,\n",
    "                val_dataloader=val_loader,\n",
    "                epochs=5,\n",
    "                monitor=\"pr_auc_samples\",\n",
    "            )\n",
    "\n",
    "            ## multi-class\n",
    "            # trainer = Trainer(model=model, device=device, metrics=[\"roc_auc_weighted_ovr\", \"cohen_kappa\", \"accuracy\", \"f1_weighted\"])\n",
    "            # trainer.train(\n",
    "            #     train_dataloader=train_loader,\n",
    "            #     val_dataloader=val_loader,\n",
    "            #     epochs=5,\n",
    "            #     monitor=\"roc_auc_weighted_ovr\",\n",
    "            # )\n",
    "\n",
    "            results[model_.__name__].append(trainer.evaluate(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = defaultdict(dict)\n",
    "\n",
    "for k, v in results.items():\n",
    "    for k_, v_ in v[0].items():\n",
    "        avg_results[k][k_] = sum([vv[k_] for vv in v]) / len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# calculate standard deviation\n",
    "variation_results = defaultdict(dict)\n",
    "\n",
    "for k, v in results.items():\n",
    "    for k_, v_ in v[0].items():\n",
    "        variation_results[k][k_] = np.std([vv[k_] for vv in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'RNN': {'pr_auc_samples': 0.6906467428253514,\n",
       "              'roc_auc_samples': 0.9246048623270761,\n",
       "              'f1_samples': 0.5444197656781944,\n",
       "              'jaccard_samples': 0.3916203471958493,\n",
       "              'loss': 0.22034245133399963}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'RNN': {'pr_auc_samples': 0.0,\n",
       "              'roc_auc_samples': 0.0,\n",
       "              'f1_samples': 0.0,\n",
       "              'jaccard_samples': 0.0,\n",
       "              'loss': 0.0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kgc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0509d9aa81f2882b18eeb72d4d23c32cae9029e9b99f63cde94ba86c35ac78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
