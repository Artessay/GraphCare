{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/kgc/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating samples for drug_recommendation_mimic4_fn: 100%|██████████| 190279/190279 [00:11<00:00, 16141.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import MIMIC3Dataset, MIMIC4Dataset\n",
    "from GraphCare.task_fn import drug_recommendation_fn, drug_recommendation_mimic4_fn, mortality_prediction_mimic3_fn, readmission_prediction_mimic3_fn, length_of_stay_prediction_mimic3_fn, length_of_stay_prediction_mimic4_fn, mortality_prediction_mimic4_fn, readmission_prediction_mimic4_fn\n",
    "\n",
    "ds = MIMIC4Dataset(\n",
    "root=\"/data/physionet.org/files/mimiciv/2.0/hosp/\", \n",
    "tables=[\"diagnoses_icd\", \"procedures_icd\", \"prescriptions\"],      \n",
    "code_mapping={\n",
    "    \"NDC\": (\"ATC\", {\"target_kwargs\": {\"level\": 3}}),\n",
    "    \"ICD9CM\": \"CCSCM\",\n",
    "    \"ICD9PROC\": \"CCSPROC\",\n",
    "    \"ICD10CM\": \"CCSCM\",\n",
    "    \"ICD10PROC\": \"CCSPROC\",\n",
    "    },\n",
    "dev=False\n",
    ")\n",
    "\n",
    "sample_dataset = ds.set_task(drug_recommendation_mimic4_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('../../../data/pj20/exp_data/ccscm_ccsproc/sample_dataset_mimic4_drugrec_th015.pkl', 'rb') as f:\n",
    "#     sample_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = split_by_patient(sample_dataset, [0.8, 0.1, 0.1], seed=528)\n",
    "train_loader = get_dataloader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = get_dataloader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = get_dataloader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embeddings): ModuleDict(\n",
      "    (conditions): Embedding(280, 128, padding_idx=0)\n",
      "    (procedures): Embedding(233, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (transformer): ModuleDict(\n",
      "    (conditions): TransformerLayer(\n",
      "      (transformer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadedAttention(\n",
      "            (linear_layers): ModuleList(\n",
      "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
      "            )\n",
      "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (attention): Attention()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (activation): GELU(approximate=none)\n",
      "          )\n",
      "          (input_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (output_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (procedures): TransformerLayer(\n",
      "      (transformer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadedAttention(\n",
      "            (linear_layers): ModuleList(\n",
      "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
      "            )\n",
      "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (attention): Attention()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (activation): GELU(approximate=none)\n",
      "          )\n",
      "          (input_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (output_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200, bias=True)\n",
      ")\n",
      "Metrics: ['pr_auc_samples', 'roc_auc_samples', 'f1_samples', 'jaccard_samples']\n",
      "Device: cuda:1\n",
      "\n",
      "Training:\n",
      "Batch size: 64\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f8488670f40>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 5\n",
      "\n",
      "Epoch 0 / 5: 100%|██████████| 1931/1931 [00:38<00:00, 50.22it/s]\n",
      "--- Train epoch-0, step-1931 ---\n",
      "loss: 0.2427\n",
      "Evaluation: 100%|██████████| 244/244 [00:02<00:00, 101.25it/s]\n",
      "--- Eval epoch-0, step-1931 ---\n",
      "pr_auc_samples: 0.6999\n",
      "roc_auc_samples: 0.9291\n",
      "f1_samples: 0.5484\n",
      "jaccard_samples: 0.3948\n",
      "loss: 0.2149\n",
      "New best pr_auc_samples score (0.6999) at epoch-0, step-1931\n",
      "\n",
      "Epoch 1 / 5: 100%|██████████| 1931/1931 [00:37<00:00, 51.69it/s]\n",
      "--- Train epoch-1, step-3862 ---\n",
      "loss: 0.2244\n",
      "Evaluation: 100%|██████████| 244/244 [00:02<00:00, 102.90it/s]\n",
      "--- Eval epoch-1, step-3862 ---\n",
      "pr_auc_samples: 0.7063\n",
      "roc_auc_samples: 0.9329\n",
      "f1_samples: 0.5525\n",
      "jaccard_samples: 0.3988\n",
      "loss: 0.2114\n",
      "New best pr_auc_samples score (0.7063) at epoch-1, step-3862\n",
      "\n",
      "Epoch 2 / 5: 100%|██████████| 1931/1931 [00:37<00:00, 51.19it/s]\n",
      "--- Train epoch-2, step-5793 ---\n",
      "loss: 0.2217\n",
      "Evaluation: 100%|██████████| 244/244 [00:02<00:00, 100.04it/s]\n",
      "--- Eval epoch-2, step-5793 ---\n",
      "pr_auc_samples: 0.7088\n",
      "roc_auc_samples: 0.9336\n",
      "f1_samples: 0.5490\n",
      "jaccard_samples: 0.3957\n",
      "loss: 0.2103\n",
      "New best pr_auc_samples score (0.7088) at epoch-2, step-5793\n",
      "\n",
      "Epoch 3 / 5: 100%|██████████| 1931/1931 [01:24<00:00, 22.94it/s]\n",
      "--- Train epoch-3, step-7724 ---\n",
      "loss: 0.2198\n",
      "Evaluation: 100%|██████████| 244/244 [00:02<00:00, 100.94it/s]\n",
      "--- Eval epoch-3, step-7724 ---\n",
      "pr_auc_samples: 0.7113\n",
      "roc_auc_samples: 0.9334\n",
      "f1_samples: 0.5545\n",
      "jaccard_samples: 0.4007\n",
      "loss: 0.2094\n",
      "New best pr_auc_samples score (0.7113) at epoch-3, step-7724\n",
      "\n",
      "Epoch 4 / 5: 100%|██████████| 1931/1931 [00:37<00:00, 50.97it/s]\n",
      "--- Train epoch-4, step-9655 ---\n",
      "loss: 0.2185\n",
      "Evaluation: 100%|██████████| 244/244 [00:02<00:00, 98.47it/s] \n",
      "--- Eval epoch-4, step-9655 ---\n",
      "pr_auc_samples: 0.7120\n",
      "roc_auc_samples: 0.9346\n",
      "f1_samples: 0.5593\n",
      "jaccard_samples: 0.4054\n",
      "loss: 0.2087\n",
      "New best pr_auc_samples score (0.7120) at epoch-4, step-9655\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 244/244 [00:02<00:00, 99.20it/s] \n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (conditions): Embedding(280, 128, padding_idx=0)\n",
      "    (procedures): Embedding(233, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (retain): ModuleDict(\n",
      "    (conditions): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (procedures): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200, bias=True)\n",
      ")\n",
      "Metrics: ['pr_auc_samples', 'roc_auc_samples', 'f1_samples', 'jaccard_samples']\n",
      "Device: cuda:1\n",
      "\n",
      "Training:\n",
      "Batch size: 64\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f8488670f40>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 5\n",
      "\n",
      "Epoch 0 / 5: 100%|██████████| 1931/1931 [01:25<00:00, 22.50it/s]\n",
      "--- Train epoch-0, step-1931 ---\n",
      "loss: 0.2290\n",
      "Evaluation: 100%|██████████| 244/244 [00:04<00:00, 58.48it/s]\n",
      "--- Eval epoch-0, step-1931 ---\n",
      "pr_auc_samples: 0.7299\n",
      "roc_auc_samples: 0.9391\n",
      "f1_samples: 0.5905\n",
      "jaccard_samples: 0.4372\n",
      "loss: 0.2061\n",
      "New best pr_auc_samples score (0.7299) at epoch-0, step-1931\n",
      "\n",
      "Epoch 1 / 5: 100%|██████████| 1931/1931 [01:30<00:00, 21.41it/s]\n",
      "--- Train epoch-1, step-3862 ---\n",
      "loss: 0.2079\n",
      "Evaluation: 100%|██████████| 244/244 [00:04<00:00, 55.66it/s]\n",
      "--- Eval epoch-1, step-3862 ---\n",
      "pr_auc_samples: 0.7364\n",
      "roc_auc_samples: 0.9414\n",
      "f1_samples: 0.5878\n",
      "jaccard_samples: 0.4350\n",
      "loss: 0.2004\n",
      "New best pr_auc_samples score (0.7364) at epoch-1, step-3862\n",
      "\n",
      "Epoch 2 / 5: 100%|██████████| 1931/1931 [01:24<00:00, 22.84it/s]\n",
      "--- Train epoch-2, step-5793 ---\n",
      "loss: 0.2048\n",
      "Evaluation: 100%|██████████| 244/244 [00:04<00:00, 57.47it/s]\n",
      "--- Eval epoch-2, step-5793 ---\n",
      "pr_auc_samples: 0.7382\n",
      "roc_auc_samples: 0.9413\n",
      "f1_samples: 0.6010\n",
      "jaccard_samples: 0.4485\n",
      "loss: 0.2001\n",
      "New best pr_auc_samples score (0.7382) at epoch-2, step-5793\n",
      "\n",
      "Epoch 3 / 5: 100%|██████████| 1931/1931 [01:28<00:00, 21.79it/s]\n",
      "--- Train epoch-3, step-7724 ---\n",
      "loss: 0.2027\n",
      "Evaluation: 100%|██████████| 244/244 [00:04<00:00, 58.45it/s]\n",
      "--- Eval epoch-3, step-7724 ---\n",
      "pr_auc_samples: 0.7418\n",
      "roc_auc_samples: 0.9428\n",
      "f1_samples: 0.5947\n",
      "jaccard_samples: 0.4422\n",
      "loss: 0.1969\n",
      "New best pr_auc_samples score (0.7418) at epoch-3, step-7724\n",
      "\n",
      "Epoch 4 / 5: 100%|██████████| 1931/1931 [01:32<00:00, 20.79it/s]\n",
      "--- Train epoch-4, step-9655 ---\n",
      "loss: 0.2013\n",
      "Evaluation: 100%|██████████| 244/244 [00:04<00:00, 59.43it/s]\n",
      "--- Eval epoch-4, step-9655 ---\n",
      "pr_auc_samples: 0.7425\n",
      "roc_auc_samples: 0.9424\n",
      "f1_samples: 0.5947\n",
      "jaccard_samples: 0.4422\n",
      "loss: 0.1961\n",
      "New best pr_auc_samples score (0.7425) at epoch-4, step-9655\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 244/244 [00:04<00:00, 56.52it/s]\n",
      "[10:50:52] Explicit valence for atom # 0 N, 4, is greater than permitted\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "import torch\n",
    "from pyhealth.models import Transformer, RETAIN, SafeDrug, MICRON, CNN, RNN, GAMENet\n",
    "from collections import defaultdict\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "for i in range(3):\n",
    "    for model_ in [\n",
    "        Transformer, \n",
    "        RETAIN,\n",
    "        SafeDrug,\n",
    "        MICRON,\n",
    "        GAMENet\n",
    "        ]:\n",
    "        try:\n",
    "            model = model_(\n",
    "                dataset=sample_dataset,\n",
    "                feature_keys=[\"conditions\", \"procedures\"],\n",
    "                label_key=\"drugs\",\n",
    "                mode=\"multilabel\",\n",
    "            )\n",
    "        except:\n",
    "            model = model_(dataset=sample_dataset)\n",
    "\n",
    "        device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        ## binary\n",
    "        # trainer = Trainer(model=model, device=device, metrics=[\"pr_auc\", \"roc_auc\", \"accuracy\", \"f1\", \"jaccard\"])\n",
    "        # trainer.train(\n",
    "        #     train_dataloader=train_loader,\n",
    "        #     val_dataloader=val_loader,\n",
    "        #     epochs=5,\n",
    "        #     monitor=\"accuracy\",\n",
    "        # )\n",
    "\n",
    "        ## multi-label\n",
    "        trainer = Trainer(model=model, device=device, metrics=[\"pr_auc_samples\", \"roc_auc_samples\", \"f1_samples\", \"jaccard_samples\"])\n",
    "        trainer.train(\n",
    "            train_dataloader=train_loader,\n",
    "            val_dataloader=val_loader,\n",
    "            epochs=5,\n",
    "            monitor=\"pr_auc_samples\",\n",
    "        )\n",
    "\n",
    "        ## multi-class\n",
    "        # trainer = Trainer(model=model, device=device, metrics=[\"roc_auc_weighted_ovr\", \"cohen_kappa\", \"accuracy\", \"f1_weighted\"])\n",
    "        # trainer.train(\n",
    "        #     train_dataloader=train_loader,\n",
    "        #     val_dataloader=val_loader,\n",
    "        #     epochs=5,\n",
    "        #     monitor=\"roc_auc_weighted_ovr\",\n",
    "        # )\n",
    "\n",
    "        results[model_.__name__].append(trainer.evaluate(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = defaultdict(dict)\n",
    "\n",
    "for k, v in results.items():\n",
    "    for k_, v_ in v[0].items():\n",
    "        avg_results[k][k_] = sum([vv[k_] for vv in v]) / len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# calculate standard deviation\n",
    "variation_results = defaultdict(dict)\n",
    "\n",
    "for k, v in results.items():\n",
    "    for k_, v_ in v[0].items():\n",
    "        variation_results[k][k_] = np.std([vv[k_] for vv in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Transformer': {'pr_auc_samples': 0.6783844682267832,\n",
       "              'roc_auc_samples': 0.9203570394645626,\n",
       "              'f1_samples': 0.5199858108988109,\n",
       "              'jaccard_samples': 0.36742235572247056,\n",
       "              'loss': 0.23415324012438457},\n",
       "             'RETAIN': {'pr_auc_samples': 0.6996383061429623,\n",
       "              'roc_auc_samples': 0.9277689975071753,\n",
       "              'f1_samples': 0.5574803101467737,\n",
       "              'jaccard_samples': 0.4039973902798657,\n",
       "              'loss': 0.2264935106039047},\n",
       "             'SafeDrug': {'pr_auc_samples': 0.5245888773670376,\n",
       "              'roc_auc_samples': 0.8686946082288995,\n",
       "              'f1_samples': 0.3472441005948089,\n",
       "              'jaccard_samples': 0.21539324480813865,\n",
       "              'loss': 0.27848473568757376},\n",
       "             'MICRON': {'pr_auc_samples': 0.7085677770407818,\n",
       "              'roc_auc_samples': 0.9289359130123493,\n",
       "              'f1_samples': 0.5626078071601712,\n",
       "              'jaccard_samples': 0.40950893439778546,\n",
       "              'loss': 0.2230909965435664},\n",
       "             'GAMENet': {'pr_auc_samples': 0.638252354515141,\n",
       "              'roc_auc_samples': 0.9076194247817977,\n",
       "              'f1_samples': 0.4966743036411138,\n",
       "              'jaccard_samples': 0.34640113165075703,\n",
       "              'loss': 0.24523823340733847}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Transformer': {'pr_auc_samples': 0.0009362267858230031,\n",
       "              'roc_auc_samples': 0.0006469108050935868,\n",
       "              'f1_samples': 0.0035958936284566606,\n",
       "              'jaccard_samples': 0.0031124661318476876,\n",
       "              'loss': 0.0006033271549201798},\n",
       "             'RETAIN': {'pr_auc_samples': 0.0012243061850607973,\n",
       "              'roc_auc_samples': 0.00031909088838670557,\n",
       "              'f1_samples': 0.0028257346084777733,\n",
       "              'jaccard_samples': 0.002540716746490498,\n",
       "              'loss': 0.0007287530945779822},\n",
       "             'SafeDrug': {'pr_auc_samples': 0.005010126702354339,\n",
       "              'roc_auc_samples': 0.001191226819088192,\n",
       "              'f1_samples': 0.009106649051422106,\n",
       "              'jaccard_samples': 0.00757658232526652,\n",
       "              'loss': 0.0007432820826128067},\n",
       "             'MICRON': {'pr_auc_samples': 0.0009596725056481872,\n",
       "              'roc_auc_samples': 0.0007391186346618564,\n",
       "              'f1_samples': 0.006902708040143838,\n",
       "              'jaccard_samples': 0.006345187544684408,\n",
       "              'loss': 0.0014630861686215136},\n",
       "             'GAMENet': {'pr_auc_samples': 0.004810962089564203,\n",
       "              'roc_auc_samples': 0.0016093571436275745,\n",
       "              'f1_samples': 0.008479337275494023,\n",
       "              'jaccard_samples': 0.007659231524252862,\n",
       "              'loss': 0.0030141883242437283}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kgc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0509d9aa81f2882b18eeb72d4d23c32cae9029e9b99f63cde94ba86c35ac78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
